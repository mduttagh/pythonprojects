{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/python\n",
    "# -*- coding: utf-8 -*-\n",
    "# Definitions\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "today = pd.to_datetime('today').normalize()\n",
    "current_eom = today + pd.offsets.MonthEnd(0)\n",
    "start_date = '2017-01-01'\n",
    "end_date = current_eom + pd.offsets.MonthEnd(11)\n",
    "\n",
    "# entity_debug = \"GBR\"\n",
    "\n",
    "debug = True\n",
    "\n",
    "\n",
    "def get_json(df):\n",
    "    \"\"\" Small function to serialise DataFrame dates as 'YYYY-MM-DD' in JSON \"\"\"\n",
    "\n",
    "    def convert_timestamp(item_date_object):\n",
    "        if isinstance(item_date_object, (datetime.date,\n",
    "                      datetime.datetime)):\n",
    "            return item_date_object.strftime('%Y-%m-%d')\n",
    "\n",
    "    dict_ = df.to_dict(orient='records')\n",
    "\n",
    "    return json.dumps(dict_, default=convert_timestamp)\n",
    "\n",
    "\n",
    "# display count and summary of any dataframe\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.expand_frame_repr', False)\n",
    "pd.set_option('max_colwidth', -1)\n",
    "pd.set_option('display.precision', 1)\n",
    "pd.set_option('display.float_format', lambda x: '%.2f' % x)\n",
    "\n",
    "\n",
    "def get_df_name(df):\n",
    "    name = [x for x in globals() if globals()[x] is df][0]\n",
    "    return name\n",
    "\n",
    "\n",
    "def difflist(li1, li2):\n",
    "    return list(set(li1) - set(li2))\n",
    "\n",
    "\n",
    "def addlist(li1, li2):\n",
    "    return li1.append(li2)\n",
    "\n",
    "\n",
    "def remove_percetage(df, column_list):\n",
    "    for col in column_list:\n",
    "        df[col] = round(df[col].str.replace('%', '').astype(np.float64)\n",
    "                        / 100, 4)\n",
    "    return df\n",
    "\n",
    "\n",
    "def coerce_df_columns_to_numeric(df):\n",
    "    cols_float1 = list(df.filter(like='Rate', axis=1).columns)\n",
    "    cols_float2 = list(df.filter(like='Yield', axis=1).columns)\n",
    "    cols_float3 = list(df.filter(like='Diff%', axis=1).columns)\n",
    "    cols_float4 = list(df.filter(like='Relative_Offset',\n",
    "                       axis=1).columns)\n",
    "    cols_float5 = list(df.filter(like='sp500', axis=1).columns)\n",
    "    cols_float6 = list(df.filter(like='Return', axis=1).columns)\n",
    "    cols_float = cols_float1 + cols_float2 + cols_float3 + cols_float4 \\\n",
    "        + cols_float5 + cols_float6\n",
    "\n",
    "    # display(\"cols_float:\", cols_float)\n",
    "\n",
    "    cols_int1 = list(df.filter(like='Revenue', axis=1).columns)\n",
    "    cols_int2 = list(df.filter(like='Conversions', axis=1).columns)\n",
    "    cols_int3 = list(df.filter(like='Value', axis=1).columns)\n",
    "    cols_int4 = list(df.filter(like='Pipeline', axis=1).columns)\n",
    "    cols_int5 = list(df.filter(like='Offset', axis=1).columns)\n",
    "    cols_int6 = list(df.filter(like='Headcount', axis=1).columns)\n",
    "    cols_int = cols_int1 + cols_int2 + cols_int3 + cols_int4 \\\n",
    "        + cols_int5 + cols_int6\n",
    "\n",
    "    # display(\"cols_int:\", cols_int)\n",
    "\n",
    "    cols1 = list(df.select_dtypes(include='float64').columns)\n",
    "    cols = cols1 + cols_int\n",
    "\n",
    "    # display(\"cols:\", cols)\n",
    "\n",
    "    final_cols = difflist(cols, cols_float)\n",
    "\n",
    "    # display(\"final_cols:\", final_cols)\n",
    "\n",
    "    df[final_cols] = df[final_cols].apply(pd.to_numeric, errors='coerce'\n",
    "            )\n",
    "    df[final_cols] = df[final_cols].replace(np.nan, 0, regex=True)\n",
    "    df[final_cols] = df[final_cols].astype(int)\n",
    "    df[final_cols] = round(df[final_cols], 0)\n",
    "\n",
    "\n",
    "    # return df\n",
    "\n",
    "def data_prep(df):\n",
    "    df.columns = df.columns.astype(str).str.replace(' ', '_')\n",
    "    if 'End_of_Month' in df.columns:\n",
    "        df['End_of_Month'] = pd.to_datetime(df['End_of_Month'])  # Format Date\n",
    "\n",
    "        # df = df.query('End_of_Month < @current_eom').reset_index(drop=True)\n",
    "\n",
    "    if 'Snapshot_Date_Short' in df.columns:\n",
    "        df['Snapshot_Date_Short'] = \\\n",
    "            pd.to_datetime(df['Snapshot_Date_Short'])  # Format Date\n",
    "\n",
    "    # #df = df.query('Fin_Entity_ID not in @exclude_studio')\n",
    "    # #df = df.query('Fin_Entity_ID not in [\"SGP\",0]') # Exclude Singapore rows\n",
    "\n",
    "    df = df.replace(np.nan, 0, regex=True)\n",
    "    return df\n",
    "\n",
    "\n",
    "def show_stats(df):\n",
    "    print (' DF Name: ')\n",
    "    display(get_df_name(df))\n",
    "    print (' DF Info: ')\n",
    "    display(df.info(verbose=True))\n",
    "    print (' DF Describe: ')\n",
    "    display(df.describe(include='all').transpose().head())\n",
    "    print (' DF Head: ')\n",
    "    display(df.head())\n",
    "    print (' DF Tail: ')\n",
    "    display(df.tail())\n",
    "\n",
    "    # group_by_entity = df.groupby(by=['Fin_Entity_ID'], as_index=False)\n",
    "    # entity_sum = group_by_entity.sum().reset_index(drop=True)\n",
    "    # entity_count = group_by_entity.count().reset_index(drop=True)\n",
    "    # print(\" Entity Sum: \")\n",
    "    # display(entity_sum.head())\n",
    "    # print(\" Studio Count: \")\n",
    "    # display(entity_count.head())\n",
    "\n",
    "    if 'End_of_Month' in df.columns:\n",
    "        df['End_of_Month'] = pd.to_datetime(df['End_of_Month'])  # Format Date\n",
    "        group_by_eom = df.groupby(by=['End_of_Month'], as_index=False)\n",
    "        eom_sum = group_by_eom.sum().reset_index(drop=True)\n",
    "        eom_count = group_by_eom.count().reset_index(drop=True)\n",
    "        print (' EOM Sum:')\n",
    "        display(eom_sum.head())\n",
    "        print (' EOM Count: ')\n",
    "        display(eom_count.head())\n",
    "    if 'Snapshot_Date_Short' in df.columns:\n",
    "        df['Snapshot_Date_Short'] = \\\n",
    "            pd.to_datetime(df['Snapshot_Date_Short'])  # Format Date\n",
    "        group_by_sds = df.groupby(by=['Snapshot_Date_Short'],\n",
    "                                  as_index=False)\n",
    "        sds_sum = group_by_sds.sum().reset_index(drop=True)\n",
    "        sds_count = group_by_sds.count().reset_index(drop=True)\n",
    "        print (' SDS Sum:')\n",
    "        display(sds_sum.head())\n",
    "        print (' SDS Count: ')\n",
    "        display(sds_count.head())\n",
    "    return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/python\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "\n",
    "def split_last_n_by_series_id(df, n):\n",
    "    \"\"\"Group df by series identifiers and split on last n rows for each group.\"\"\"\n",
    "\n",
    "    df_grouped = \\\n",
    "        df.sort_values(time_column_name).groupby(time_series_id_column_names,\n",
    "            group_keys=False)  # Sort by ascending time\n",
    "    df_head = df_grouped.apply(lambda dfg: dfg.iloc[:-n])\n",
    "    df_tail = df_grouped.apply(lambda dfg: dfg.iloc[-n:])\n",
    "    return (df_head, df_tail)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def APE(actual, pred):\n",
    "    \"\"\"\n",
    "    Calculate absolute percentage error.\n",
    "    Returns a vector of APE values with same length as actual/pred.\n",
    "    \"\"\"\n",
    "\n",
    "    return 100 * np.abs((actual - pred) / actual)\n",
    "\n",
    "\n",
    "def MAPE(actual, pred):\n",
    "    \"\"\"\n",
    "    Calculate mean absolute percentage error.\n",
    "    Remove NA and values where actual is close to zero\n",
    "    \"\"\"\n",
    "\n",
    "    not_na = ~(np.isnan(actual) | np.isnan(pred))\n",
    "    not_zero = ~np.isclose(actual, 0.0)\n",
    "    actual_safe = actual[not_na & not_zero]\n",
    "    pred_safe = pred[not_na & not_zero]\n",
    "    return np.mean(APE(actual_safe, pred_safe))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/python\n",
    "# -*- coding: utf-8 -*-\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas.tseries.frequencies import to_offset\n",
    "\n",
    "\n",
    "def align_outputs(\n",
    "    y_predicted,\n",
    "    X_trans,\n",
    "    X_test,\n",
    "    y_test,\n",
    "    target_column_name,\n",
    "    predicted_column_name='predicted',\n",
    "    horizon_colname='horizon_origin',\n",
    "    ):\n",
    "    \"\"\"\n",
    "    Demonstrates how to get the output aligned to the inputs\n",
    "    using pandas indexes. Helps understand what happened if\n",
    "    the output's shape differs from the input shape, or if\n",
    "    the data got re-sorted by time and grain during forecasting.\n",
    "\n",
    "    Typical causes of misalignment are:\n",
    "    * we predicted some periods that were missing in actuals -> drop from eval\n",
    "    * model was asked to predict past max_horizon -> increase max horizon\n",
    "    * data at start of X_test was needed for lags -> provide previous periods\n",
    "    \"\"\"\n",
    "\n",
    "    if horizon_colname in X_trans:\n",
    "        df_fcst = pd.DataFrame({predicted_column_name: y_predicted,\n",
    "                               horizon_colname: X_trans[horizon_colname]})\n",
    "    else:\n",
    "        df_fcst = pd.DataFrame({predicted_column_name: y_predicted})\n",
    "\n",
    "    # y and X outputs are aligned by forecast() function contract\n",
    "\n",
    "    df_fcst.index = X_trans.index\n",
    "\n",
    "    # align original X_test to y_test\n",
    "\n",
    "    X_test_full = X_test.copy()\n",
    "    X_test_full[target_column_name] = y_test\n",
    "\n",
    "    # X_test_full's index does not include origin, so reset for merge\n",
    "\n",
    "    df_fcst.reset_index(inplace=True)\n",
    "    X_test_full = X_test_full.reset_index().drop(columns='index')\n",
    "    together = df_fcst.merge(X_test_full, how='right')\n",
    "\n",
    "    # drop rows where prediction or actuals are nan\n",
    "    # happens because of missing actuals\n",
    "    # or at edges of time due to lags/rolling windows\n",
    "\n",
    "    clean = together[together[[target_column_name,\n",
    "                     predicted_column_name]].notnull().all(axis=1)]\n",
    "    return clean\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/python\n",
    "# -*- coding: utf-8 -*-\n",
    "import pandas as pd\n",
    "from azureml.core import Environment\n",
    "from azureml.core.conda_dependencies import CondaDependencies\n",
    "from azureml.train.estimator import Estimator\n",
    "from azureml.core.run import Run\n",
    "from azureml.automl.core.shared import constants\n",
    "\n",
    "\n",
    "def split_fraction_by_grain(\n",
    "    df,\n",
    "    fraction,\n",
    "    time_column_name,\n",
    "    grain_column_names=None,\n",
    "    ):\n",
    "    if not grain_column_names:\n",
    "        df['tmp_grain_column'] = 'grain'\n",
    "        grain_column_names = ['tmp_grain_column']\n",
    "\n",
    "    df_grouped = \\\n",
    "        df.sort_values(time_column_name).groupby(grain_column_names,\n",
    "            group_keys=False)\n",
    "\n",
    "    df_head = df_grouped.apply(lambda dfg: (dfg.iloc[:-int(len(dfg)\n",
    "                               * fraction)] if fraction > 0 else dfg))\n",
    "\n",
    "    df_tail = df_grouped.apply(lambda dfg: (dfg.iloc[-int(len(dfg)\n",
    "                               * fraction):] if fraction\n",
    "                               > 0 else dfg[:0]))\n",
    "\n",
    "    if 'tmp_grain_column' in grain_column_names:\n",
    "        for df2 in (df, df_head, df_tail):\n",
    "            df2.drop('tmp_grain_column', axis=1, inplace=True)\n",
    "\n",
    "        grain_column_names.remove('tmp_grain_column')\n",
    "\n",
    "    return (df_head, df_tail)\n",
    "\n",
    "\n",
    "def split_full_for_forecasting(\n",
    "    df,\n",
    "    time_column_name,\n",
    "    grain_column_names=None,\n",
    "    test_split=0.2,\n",
    "    ):\n",
    "    index_name = df.index.name\n",
    "\n",
    "    # Assumes that there isn't already a column called tmpindex\n",
    "\n",
    "    df['tmpindex'] = df.index\n",
    "\n",
    "    (train_df, test_df) = split_fraction_by_grain(df, test_split,\n",
    "            time_column_name, grain_column_names)\n",
    "\n",
    "    train_df = train_df.set_index('tmpindex')\n",
    "    train_df.index.name = index_name\n",
    "\n",
    "    test_df = test_df.set_index('tmpindex')\n",
    "    test_df.index.name = index_name\n",
    "\n",
    "    df.drop('tmpindex', axis=1, inplace=True)\n",
    "\n",
    "    return (train_df, test_df)\n",
    "\n",
    "\n",
    "def get_result_df(remote_run):\n",
    "    children = list(remote_run.get_children(recursive=True))\n",
    "    summary_df = pd.DataFrame(index=['run_id', 'run_algorithm',\n",
    "                              'primary_metric', 'Score'])\n",
    "    goal_minimize = False\n",
    "    for run in children:\n",
    "        if run.get_status().lower() == constants.RunState.COMPLETE_RUN \\\n",
    "            and 'run_algorithm' in run.properties and 'score' \\\n",
    "            in run.properties:\n",
    "\n",
    "            # We only count in the completed child runs.\n",
    "\n",
    "            summary_df[run.id] = [run.id, run.properties['run_algorithm'\n",
    "                                  ], run.properties['primary_metric'],\n",
    "                                  float(run.properties['score'])]\n",
    "            if 'goal' in run.properties:\n",
    "                goal_minimize = run.properties['goal'].split('_')[-1] \\\n",
    "                    == 'min'\n",
    "\n",
    "    summary_df = summary_df.T.sort_values('Score',\n",
    "            ascending=goal_minimize).drop_duplicates(['run_algorithm'])\n",
    "    summary_df = summary_df.set_index('run_algorithm')\n",
    "    return summary_df\n",
    "\n",
    "\n",
    "def run_inference(\n",
    "    test_experiment,\n",
    "    compute_target,\n",
    "    script_folder,\n",
    "    train_run,\n",
    "    test_dataset,\n",
    "    lookback_dataset,\n",
    "    max_horizon,\n",
    "    target_column_name,\n",
    "    time_column_name,\n",
    "    freq,\n",
    "    ):\n",
    "\n",
    "    model_base_name = 'model.pkl'\n",
    "    if 'model_data_location' in train_run.properties:\n",
    "        model_location = train_run.properties['model_data_location']\n",
    "        (_, model_base_name) = model_location.rsplit('/', 1)\n",
    "    train_run.download_file('outputs/{}'.format(model_base_name),\n",
    "                            'inference/{}'.format(model_base_name))\n",
    "    train_run.download_file('outputs/conda_env_v_1_0_0.yml',\n",
    "                            'inference/condafile.yml')\n",
    "\n",
    "    inference_env = Environment('myenv')\n",
    "    inference_env.docker.enabled = True\n",
    "    inference_env.python.conda_dependencies = \\\n",
    "        CondaDependencies(conda_dependencies_file_path='inference/condafile.yml'\n",
    "                          )\n",
    "\n",
    "    est = Estimator(\n",
    "        source_directory=script_folder,\n",
    "        entry_script='infer.py',\n",
    "        script_params={\n",
    "            '--max_horizon': max_horizon,\n",
    "            '--target_column_name': target_column_name,\n",
    "            '--time_column_name': time_column_name,\n",
    "            '--frequency': freq,\n",
    "            '--model_path': model_base_name,\n",
    "            },\n",
    "        inputs=[test_dataset.as_named_input('test_data'),\n",
    "                lookback_dataset.as_named_input('lookback_data')],\n",
    "        compute_target=compute_target,\n",
    "        environment_definition=inference_env,\n",
    "        )\n",
    "\n",
    "    run = test_experiment.submit(est, tags={\n",
    "        'training_run_id': train_run.id,\n",
    "        'run_algorithm': train_run.properties['run_algorithm'],\n",
    "        'valid_score': train_run.properties['score'],\n",
    "        'primary_metric': train_run.properties['primary_metric'],\n",
    "        })\n",
    "\n",
    "    run.log('run_algorithm', run.tags['run_algorithm'])\n",
    "    return run\n",
    "\n",
    "\n",
    "def run_multiple_inferences(\n",
    "    summary_df,\n",
    "    train_experiment,\n",
    "    test_experiment,\n",
    "    compute_target,\n",
    "    script_folder,\n",
    "    test_dataset,\n",
    "    lookback_dataset,\n",
    "    max_horizon,\n",
    "    target_column_name,\n",
    "    time_column_name,\n",
    "    freq,\n",
    "    ):\n",
    "\n",
    "    for (run_name, run_summary) in summary_df.iterrows():\n",
    "        print (run_name)\n",
    "        print (run_summary)\n",
    "        run_id = run_summary.run_id\n",
    "        train_run = Run(train_experiment, run_id)\n",
    "\n",
    "        test_run = run_inference(\n",
    "            test_experiment,\n",
    "            compute_target,\n",
    "            script_folder,\n",
    "            train_run,\n",
    "            test_dataset,\n",
    "            lookback_dataset,\n",
    "            max_horizon,\n",
    "            target_column_name,\n",
    "            time_column_name,\n",
    "            freq,\n",
    "            )\n",
    "\n",
    "        print (test_run)\n",
    "\n",
    "        summary_df.loc[summary_df.run_id == run_id, 'test_run_id'] = \\\n",
    "            test_run.id\n",
    "\n",
    "    return summary_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3-azureml"
  },
  "kernelspec": {
   "display_name": "Python 3.6 - AzureML",
   "language": "python",
   "name": "python3-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
