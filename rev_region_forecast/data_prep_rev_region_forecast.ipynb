{"cells":[{"cell_type":"code","source":["\n","# define widgets - NEED TO DEFINE IT ONCE\n","# dynamic variables (pass it from ADF)\n","# first time runtime parameter\n","# dbutils.widgets.dropdown(\"environment\", \"dev\", [\"dev\",\"uat\",\"prod\"])\n","# dbutils.widgets.dropdown(\"new_training\", \"False\", [\"True\",\"False\"])\n","# dbutils.widgets.dropdown(\"system_name\", \"bimodelapi\", [\"bimodelapi\"])\n","# dbutils.widgets.text(\"system_name\", \"\",\"\")\n","# dbutils.widgets.remove(\"pbiapi\")\n","environment = dbutils.widgets.get(\"environment\")\n","new_training = dbutils.widgets.get(\"new_training\")\n","system_name = dbutils.widgets.get(\"system_name\")\n","if environment in {\"prod\"}:\n","    aml_compute_cluster_name = \"cc-bi-ml-prod01\"\n","else:\n","    aml_compute_cluster_name = \"cc-bi-ml-devqa01\"\n","\n","print(environment, system_name, new_training, aml_compute_cluster_name)\n","\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"a4950dd8-104e-4dd1-a7c1-e4c4e28a74a3"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":["%run ./data_load_rev_region_forecast"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"9489c9e1-c3c0-4f7a-9da8-9d32c1ee9219"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":["# Prepare Data & Set time column and series columns\n","print(\"Preparing data\")\n","# set variales\n","\n","target_column_name = \"Revenue\"\n","time_column_name = \"End_of_Month\"\n","time_series_id_column_names = [\"Relative_Offset\", \"Sub_Region_Code\"]\n","sort_cols_snp = [\"End_of_Month\", \"Snapshot_Date\", \"Sub_Region_Code\"]\n","sort_cols_eom = [\"End_of_Month\", \"Sub_Region_Code\"]\n","\n","exclude_sub_region = [\"Singapore\", \"NA\"]\n","\n","pd.set_option(\"display.float_format\", lambda x: \"%.2f\" % x)\n","\n","talenthist1 = talenthist.copy()  # .toPandas() to convert from spark df to pandas\n","pipehist1 = pipehist.copy()\n","opphist1 = opphist.copy()\n","projhist1 = projhist.copy()\n","revhist1 = revhist.copy()\n","pipetrend1 = pipetrend.copy()\n","projectactualshist1 = projectactualshist.copy()\n","\n","# pipetrend1.drop(columns=\"Snapshot_Date_Short\", axis=1, inplace=True)\n","\n","pipehist1.rename(columns={\"Snapshot_Date_Short\": \"Snapshot_Date\"}, inplace=True)\n","pipetrend1.rename(columns={\"Snapshot_Date_Short\": \"Snapshot_Date\"}, inplace=True)\n","pipetrend1.rename(columns={\"Snapshot_End_of_Month\": \"End_of_Month\"}, inplace=True)\n","#talenthist1[\"Billable_Headcount\"] = (\n","#    talenthist1[\"Headcount\"] + talenthist1[\"Headcount_Contingent\"]\n","#)\n","#talenthist1.drop(columns=[\"Headcount\"], axis=1, inplace=True)\n","\n","numeric_cols = [\n","    \"Pipeline\",\n","    \"Pipeline_at_100_Percent\",\n","    \"Yield\",\n","    \"Pipeline_Trend\",\n","    \"Revenue\",\n","    \"Project_Period_Count\",\n","    \"Project_Count\",\n","    \"Project_Period_Price\",\n","    \"Project_Price\",\t\n","    \"Conversions\",\n","    \"Opportunity_Period_Count\",\n","    \"Opportunity_Count\",\n","    \"Current_Opp._Period_Value\",\n","    'Opportunity Value',\n","    \"Win_Rate\",\n","    \"Headcount\",\n","    \"Utilization_Billable\"\n","]\n","\n","df_list = [\n","    pipehist1,\n","    talenthist1,\n","    revhist1,\n","    opphist1,\n","    projhist1,\n","    pipetrend1,\n","    projectactualshist1\n","]\n","for x in df_list:\n","    x.infer_objects()\n","\n","    # convert date to to_datetime\n","\n","    x = convert_date_cols(x)\n","\n","    # coerce numeric_cols to numeric\n","    x = coerce_to_numeric(x)\n","\n","    # replace null values to NA\n","\n","    x[\"Sub_Region_Code\"] = x[\"Sub_Region_Code\"].replace(np.nan, \"NA\", regex=True)\n","\n","    x = x.replace(np.nan, 0, regex=True)\n","\n","    # make all dates to End of Month values to later merge\n","    if \"End_of_Month\" in x.columns:\n","\n","        x[\"End_of_Month\"] = x[\"End_of_Month\"] + pd.offsets.MonthEnd(0)\n","\n","    if \"Snapshot_Date\" in x.columns:\n","\n","        # x['Snapshot_Date'] = x['Snapshot_Date'] + pd.offsets.MonthEnd(0)\n","\n","        x.sort_values(by=[\"End_of_Month\", \"Snapshot_Date\", \"Sub_Region_Code\"]).reset_index(drop=True)\n","    else:\n","        x.sort_values(by=sort_cols_eom).reset_index(drop=True)\n","    \n","    print(get_df_name(x), \":\", x.shape)\n","    '''\n","    display(x.info())\n","    display(x.tail())\n","    '''\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"1e3e163a-f5de-4073-8b00-3da371ce6f66"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":["\n","# Cross join to get cross-join of all unquie values of End_of_Month + Relative_Offset + Snp_Seq_No + Sub_Region_Code with forward filling the last snapshot date for that relative_month\n","print(\"Preparing eom_region_snp_final\")\n","# Set Parameters---------------------------------------------------------------------------------------------------------------------\n","\n","past_period = 12\n","n_test_periods = 4\n","nan_value = 0\n","dt1 = pd.to_datetime('2018-07-31') #ignore revenues before pipeline data was not there\n","\n","main_filter = \"Relative_Offset >= -@past_period and \\\n","                Relative_Offset < @n_test_periods and \\\n","                Relative_Snapshot_Month_Offset <= 0 and \\\n","                Snp_Seq_No == 6\"\n","\n","d = pd.date_range(start_date, today + pd.offsets.MonthEnd(n_test_periods), freq=\"m\")\n","eom = pd.DataFrame(d, columns=[\"End_of_Month\"])\n","\n","# eom = pipehist_pivot1[['End_of_Month']].drop_duplicates(subset='End_of_Month',keep='last').sort_values(by=['End_of_Month']).reset_index(drop=True)\n","\n","sub_region = pd.DataFrame(\n","    pipehist1[\"Sub_Region_Code\"].unique(), columns=[\"Sub_Region_Code\"]\n",")\n","snp_date = pd.DataFrame(pipehist1[\"Snapshot_Date\"].unique(), columns=[\"Snapshot_Date\"])\n","\n","eom1 = df_crossjoin(snp_date, eom)\n","eom1 = eom1.reset_index(drop=True)\n","\n","eom2 = df_crossjoin(eom1, sub_region)\n","eom2 = eom2.reset_index(drop=True)\n","# eom1 = eom.merge(snp_date, how=\"cross\")\n","# eom2 = eom1.merge(sub_region, how=\"cross\")\n","\n","\n","eom_region_snp = eom2.replace(np.nan, \"NA\", regex=True).query(\n","    \"Sub_Region_Code not in @exclude_sub_region\"\n",")\n","eom_region_snp = eom_region_snp.reset_index(drop=True)\n","# eom_region_snp.drop(columns=['key'], axis=1, inplace = True)\n","\n","# Add offset columns\n","\n","eom_region_snp[\"Relative_Month_Offset\"] = round(\n","    (eom_region_snp[\"End_of_Month\"] - current_eom) / np.timedelta64(1, \"M\"), 0\n",").astype(int)\n","eom_region_snp[\"Relative_Snapshot_Month_Offset\"] = round(\n","    (eom_region_snp[\"Snapshot_Date\"] + pd.offsets.MonthEnd(0) - current_eom)\n","    / np.timedelta64(1, \"M\"),\n","    0,\n",").astype(int)\n","eom_region_snp[\"Relative_Offset\"] = (\n","    eom_region_snp[\"Relative_Month_Offset\"] -\n","    eom_region_snp[\"Relative_Snapshot_Month_Offset\"]\n",")\n","eom_region_snp[\"Relative_Offset\"] = eom_region_snp[\"Relative_Offset\"].astype(int)\n","eom_region_snp[\"Snapshot_Day_of_Month\"] = eom_region_snp[\"Snapshot_Date\"].dt.day\n","\n","eom_region_snp1 = eom_region_snp.copy()\n","\n","# display(eom_region_snp.tail())\n","\n","# Add a sequence number to each element in a group using python\n","seq = pd.DataFrame()\n","seq[\"Snp_Seq_No\"] = [0, 1, 2, 3, 4, 5, 6]\n","\n","eom_region_snp1 = eom_region_snp1.sort_values(by=[\"End_of_Month\", \"Snapshot_Date\", \"Sub_Region_Code\"]).reset_index(drop=True)\n","#print(\"eom_region_snp1:\")\n","#eom_region_snp1.info()\n","#display(eom_region_snp1.tail())\n","\n","eom_region_snp2 = (\n","    eom_region_snp1[[\"End_of_Month\", \"Relative_Offset\", \"Snapshot_Date\"]]\n","    .groupby([\"End_of_Month\", \"Relative_Offset\", \"Snapshot_Date\"])\n","    .last()\n",")\n","\n","# eom_region_snp['Snp_Seq_No'] = normalize(eom_region_snp['Snapshot_Date'].dt.day,1,15) #Normalizing from one range to another\n","\n","eom_region_snp2[\"Snp_Seq_No\"] = eom_region_snp2.groupby(\n","    [\"End_of_Month\", \"Relative_Offset\"]\n",").cumcount()\n","\n","cols1 = [\"End_of_Month\", \"Relative_Offset\"]\n","eom_offset_region = eom_region_snp1[cols1].drop_duplicates()\n","eom_offset_seq = df_crossjoin(eom_offset_region, seq)\n","\n","#display(eom_offset_seq)\n","eom_region_snp2 = eom_region_snp2.reset_index(\n","    level=eom_region_snp2.index.names\n",").reset_index(drop=True)\n","\n","#print(\"eom_region_snp2:\")\n","#eom_region_snp2.info()\n","#display(eom_region_snp2)\n","#display(seq.info())\n","\n","eom_region_snp3 = pd.merge(\n","    eom_offset_seq,\n","    eom_region_snp2,\n","    how = \"left\",\n","    on=[\"End_of_Month\",\"Relative_Offset\",\"Snp_Seq_No\"]\n",")\n","eom_region_snp3 = eom_region_snp3.reset_index(drop=True)\n","#print(\"eom_region_snp3:\")\n","#display(eom_region_snp3.info())\n","\n","#display(eom_region_snp3.tail())\n","\n","eom_region_snp3 = eom_region_snp3.ffill(axis=0)\n","\n","eom_region_snp_final = pd.merge(\n","    eom_region_snp1,\n","    eom_region_snp3,\n","    how=\"right\",\n","    on=[\"End_of_Month\", \"Relative_Offset\", \"Snapshot_Date\"],\n",").fillna(nan_value)\n","eom_region_snp_final = eom_region_snp_final.reset_index(drop=True)\n","\n","eom_region_snp_final = eom_region_snp_final.replace(np.nan, 0, regex=True)\n","#print(\"eom_region_snp_final:\")\n","#display(eom_region_snp_final.info())\n","\n","int_cols = [\n","    \"Relative_Snapshot_Month_Offset\",\n","    \"Relative_Month_Offset\",\n","    \"Relative_Offset\",\n","    \"Snp_Seq_No\",\n","    \"Snapshot_Day_of_Month\"\n","]\n","\n","eom_region_snp_final = coerce_to_int(eom_region_snp_final)\n","\n","\n","# FILTER for relevant history and forecast period rows\n","eom_region_snp_final = eom_region_snp_final.query(main_filter).sort_values(by=sort_cols_snp).reset_index(drop=True)\n","\n","eom_region_snp_final.to_csv(output_data_path + \"eom_region_snp.csv\", index=False)\n","\n","print(\"eom_region_snp_final:\")\n","#eom_region_snp_final['End_of_Month'].unique()\n","eom_region_snp_final.info()\n","eom_region_snp_final.tail()\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"7a3a4d16-1dc5-489a-bd82-82dbaa865034"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":["pd.DataFrame(eom_region_snp_final.describe(include='all').transpose().head())\n","#'''\n","eom_region_snp_pvt = eom_region_snp_final.pivot_table(\n","    index=[time_column_name, \"Relative_Offset\"],\n","    columns=[\"Snp_Seq_No\", \"Sub_Region_Code\"],\n","    values=[\"Snapshot_Date\"],\n","    aggfunc={\"Snapshot_Date\": \"count\"},\n","    margins=False,\n",")\n","# eom_region_snp_pvt = eom_region_snp_pvt.reset_index(level=eom_region_snp_pvt.index.names).reset_index(drop=True)\n","eom_region_snp_pvt\n","#'''"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"08e9a999-e1ad-4f11-a78b-6ea42aa2527e"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":["\n","# Pivot Talent from long to wide to match month end grain\n","print(\"Preparing talent wide\")\n","nan_value = 0\n","#display(talenthist1.tail())\n","\n","talenthist_wide1 = talenthist1.pivot_table(\n","    index=[\"End_of_Month\", \"Sub_Region_Code\"],\n","    columns=[\"Billable\", \"Journey_Level\"],\n","    values=[\"Headcount\"],\n","    aggfunc={\"Headcount\": np.sum},\n","    margins=False,\n",").fillna(nan_value)\n","\n","\n","talenthist_wide1.columns = [\n","    \"_\".join(tuple(map(str, t))) for t in talenthist_wide1.columns.values\n","]\n","\n","talenthist_wide1.reset_index(inplace=True)\n","talent_cols1 = talenthist_wide1.columns\n","remove_list1 = [\"End_of_Month\", \"Sub_Region_Code\", \"Headcount\"]\n","talent_cols1 = difflist(talent_cols1, remove_list1)\n","#print(talent_cols1)\n","\n","# Sum contingent at month, billable, sub-region level\n","talenthist_wide2 = talenthist1.pivot_table(\n","    index=[\"End_of_Month\", \"Sub_Region_Code\"],\n","    columns=[\"Billable\"],\n","    values=[\"Headcount_Contingent\"],\n","    aggfunc={\"Headcount_Contingent\": np.sum},\n","    margins=False,\n",").fillna(nan_value)\n","\n","talenthist_wide2.columns = [\n","    \"_\".join(tuple(map(str, t))) for t in talenthist_wide2.columns.values\n","]\n","\n","talenthist_wide2.reset_index(inplace=True)\n","talent_cols2 = talenthist_wide2.columns\n","remove_list2 = [\"End_of_Month\", \"Sub_Region_Code\", \"Headcount_Contingent\"]\n","talent_cols2 = difflist(talent_cols2, remove_list2)\n","#print(talent_cols2)\n","\n","# talenthist_wide.tail()\n","# pipetrend_wide['Pipeline'] = pd.to_numeric(pipetrend_wide['Pipeline'], errors='coerce').astype(int)\n","\n","talent_cols = talent_cols1 + talent_cols2\n","numeric_cols_talent = numeric_cols\n","numeric_cols_talent = numeric_cols_talent + talent_cols\n","numeric_cols = numeric_cols_talent\n","print(numeric_cols)\n","\n","talenthist_wide1 = coerce_to_numeric(talenthist_wide1)\n","talenthist_wide1 = convert_date_cols(talenthist_wide1)\n","talenthist_wide1 = talenthist_wide1.sort_values(by=sort_cols_eom).reset_index(drop=True)\n","\n","talenthist_wide2 = coerce_to_numeric(talenthist_wide2)\n","talenthist_wide2 = convert_date_cols(talenthist_wide2)\n","talenthist_wide2 = talenthist_wide2.sort_values(by=sort_cols_eom).reset_index(drop=True)\n","\n","# print(' pipetrend_wide: ')\n","\n","#display(talenthist_wide1.info())\n","#display(talenthist_wide2.info())\n","'''\n","# pipetrend_wide.query('Fin_Entity_ID==@entity_debug')\n","#print(\"talenthist_wide:\", talenthist_wide.shape)\n","#talenthist_wide.tail()  # .query('Relative_Snapshot_Month_Offset == 0')\n","'''"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"cdc386b6-a520-4680-8e6b-1e6b0e7f4a38"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":["\n","# Pivot ProjectActuals from long to wide to match month end grain\n","print(\"Preparing ProjectActuals wide\")\n","nan_value = 0\n","\n","projectactualshist_wide = projectactualshist1.pivot_table(\n","    index=[\"End_of_Month\", \"Sub_Region_Code\"],\n","    columns=\"Journey_Level\",\n","    values=[\"Utilization_Billable\"],\n","    aggfunc={\"Utilization_Billable\": np.sum},\n","    margins=False,\n",").fillna(nan_value)\n","\n","\n","projectactualshist_wide.columns = [\n","    \"_\".join(tuple(map(str, t))) for t in projectactualshist_wide.columns.values\n","]\n","\n","projectactualshist_wide.reset_index(inplace=True)\n","projectactuals_cols = projectactualshist_wide.columns\n","remove_list = [\"End_of_Month\", \"Sub_Region_Code\", \"Utilization_Billable\"]\n","projectactuals_cols = difflist(projectactuals_cols, remove_list)\n","#print(projectactuals_cols)\n","    \n","numeric_cols_projectactuals = numeric_cols\n","numeric_cols_projectactuals = numeric_cols_projectactuals + projectactuals_cols\n","print(numeric_cols_projectactuals)\n","\n","numeric_cols = numeric_cols_projectactuals\n","projectactualshist_wide = coerce_to_numeric(projectactualshist_wide)\n","projectactualshist_wide = convert_date_cols(projectactualshist_wide)\n","projectactualshist_wide = projectactualshist_wide.sort_values(by=sort_cols_eom).reset_index(drop=True)\n","\n","# print(' projectactualshist_wide: ')\n","\n","display(projectactualshist_wide.info())\n","#display(projectactualshist_wide.tail())\n","'''\n","# projectactualshist_wide.query('Fin_Entity_ID==@entity_debug')\n","print(\"projectactualshist_wide:\", projectactualshist_wide.shape)\n","'''\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"e8725c1f-4590-415f-97df-4ab7e9fc566b"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":["\n","# Pivot Pipeline_Trend from long to wide to match month end grain\n","'''\n","print(\"Preparing Pipeline_Trend Wide\")\n","\n","nan_value = 0\n","pipetrend_wide = pipetrend1.pivot_table(\n","    index=[\"Snapshot_Date\", \"End_of_Month\", \"Sub_Region_Code\"],\n","    columns=\"Pipeline_Type\",\n","    values=[\"Pipeline_Trend\"],  # , 'Pipeline_3M_Rolling_Avg'\n","    aggfunc={\"Pipeline_Trend\": np.sum},\n","    margins=False,\n",").fillna(nan_value)\n","\n","\n","pipetrend_wide.columns = [\n","    \"_\".join(tuple(map(str, t))) for t in pipetrend_wide.columns.values\n","]\n","\n","pipe_cols = [\n","    \"Active_Unrecognized_Trend\",\n","    \"Opportunity_Trend\",\n","    \"Opportunity_ML_Trend\",  # ,    \"Recognized\",\n","]\n","\n","pipetrend_wide.columns = pipe_cols\n","\n","pipetrend_wide = pipetrend_wide.reset_index(\n","    level=pipetrend_wide.index.names\n",").reset_index(drop=True)\n","\n","numeric_cols_pipetrend = numeric_cols\n","numeric_cols_pipetrend = numeric_cols_pipetrend + pipe_cols\n","if \"Pipeline_Trend\" in numeric_cols_pipetrend:\n","    numeric_cols_pipetrend.remove(\"Pipeline_Trend\")\n","print(numeric_cols_pipetrend)\n","\n","numeric_cols = numeric_cols_pipetrend\n","pipetrend_wide = convert_date_cols(pipetrend_wide)\n","pipetrend_wide = coerce_to_numeric(pipetrend_wide)\n","pipetrend_wide = coerce_to_int(pipetrend_wide)\n","\n","pipetrend_wide = pipetrend_wide.sort_values(by=[\"Snapshot_Date\", \"End_of_Month\", \"Sub_Region_Code\"]).reset_index(drop=True)\n","\n","# print(' pipetrend_wide: ')\n","\n","display(pipetrend_wide.info())\n","\n","# pipetrend_wide.query('Fin_Entity_ID==@entity_debug')\n","print(\"pipetrend_wide:\", pipetrend_wide.shape)\n","#pipetrend_wide.tail()  # .query('Relative_Snapshot_Month_Offset == 0')\n","\n","'''"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"c028d1f1-536d-451a-8cab-a58ccd61ee59"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":["\n","# Merge eom_studio with Revenue, Talent, Opportunity, Project\n","print(\"Preparing merge_df\")\n","from functools import reduce\n","\n","nan_value = 0\n","merge_dfs = [eom_region_snp_final, revhist1, talenthist_wide1, talenthist_wide2, opphist1, projhist1, projectactualshist_wide]\n","\n","merge_df = reduce(\n","    lambda left, right: pd.merge(\n","        left, right, how=\"left\", on=[\"End_of_Month\", \"Sub_Region_Code\"]\n","    ),\n","    merge_dfs,\n",").fillna(nan_value)\n","\n","\n","merge_df = convert_date_cols(merge_df)\n","merge_df = coerce_to_numeric(merge_df)\n","merge_df = coerce_to_int(merge_df)\n","\n","merge_df = merge_df.replace(np.nan, 0, regex=True)\n","merge_df.sort_values(by=sort_cols_snp).reset_index(drop=True)\n","\n","# merge_df.drop(columns=['Current_Opp._Period_Value','Conversions'], axis=1, inplace = True)\n","\n","#print(\" merge_df: \", merge_df.shape)\n","\n","# merge_df.to_csv(output_data_path   'merge_df.csv', index=False)\n","# show_stats(merge_df)\n","merge_df.info()\n","#print(merge_df.shape)\n","#merge_df.tail()  # .query('Fin_Entity_ID==@entity_debug')')\n","\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"e994fd4f-8c45-4f90-b26c-ae87bc5883b6"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":["\n","# Merge with eom_region_snp1 with stock_final_pivot\n","print(\"Preparing merge_df1\")\n","# eom1 = eom  # pd.DataFrame(d, columns=['End_of_Month'])\n","# stock_final_df = pd.merge(\n","#    eom_region_snp1, stock_final_pivot, how=\"left\", on=[\"End_of_Month\",\"Relative_Month_Offset\",\"Relative_Snapshot_Month_Offset\",\"Relative_Offset\"]\n","# ).fillna(nan_value)\n","\n","# sp500_df = sp500_df.ffill(axis = 0)\n","\n","# stock_final_df = stock_final_df.sort_values(by=sort_cols_eom).reset_index(drop=True)\n","# display(sp500_df.tail(10))\n","merge_df1 = pd.merge(merge_df, stock_final_pivot, how=\"left\", on=\"End_of_Month\").fillna(\n","    nan_value\n",")\n","print(symbols_name)\n","\n","numeric_cols_stock = numeric_cols\n","numeric_cols_stock = numeric_cols_stock + symbols_name\n","#if \"Pipeline_Trend\" in numeric_cols_stock:\n","#    numeric_cols_stock.remove(\"Pipeline_Trend\")\n","print(numeric_cols_stock)\n","\n","numeric_cols = numeric_cols_stock\n","merge_df1 = convert_date_cols(merge_df1)\n","merge_df1 = coerce_to_numeric(merge_df1)\n","merge_df1 = coerce_to_int(merge_df1)\n","\n","merge_df1 = merge_df1.sort_values(by=sort_cols_snp).reset_index(drop=True)\n","# merge_df1.to_csv(output_data_path   'merge_df1.csv', index=False)\n","# merge_sdf1 = spark.createDataFrame(merge_df1);\n","# merge_sdf1.write.format(\"parquet\").mode(\"overwrite\").parquet(output_data_path   'merge_df1.parquet')\n","\n","# show_stats(merge_df1.tail(10))\n","# merge_df1.info()\n","#print(merge_df1.shape)\n","merge_df1.info()\n","#merge_df1.tail()\n","\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"3cd7e85b-26dd-4a7b-a7a1-e598628fe333"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":["\n","# Pivot Pipeline_Type from long to wide to match month end grain\n","print(\"Preparing pipehist_wide\")\n","pipehist_long = pipehist1.copy()\n","pipehist_wide = pipehist_long.pivot_table(\n","    index=[\n","        \"Snapshot_Date\",\n","        \"Relative_Snapshot_Month_Offset\",\n","        \"End_of_Month\",\n","        \"Relative_Month_Offset\",\n","        \"Sub_Region_Code\"\n","    ],\n","    columns=\"Pipeline_Type\",\n","    values=[\"Pipeline\", \"Pipeline_at_100_Percent\", \"Yield\"],  # , 'Pipeline_3M_Rolling_Avg'\n","    # aggfunc={\"Pipeline\": np.sum},\n","    margins=False,\n",").fillna(nan_value)\n","\n","pipehist_wide.columns = [\n","    \"_\".join(tuple(map(str, t))) for t in pipehist_wide.columns.values\n","]\n","\n","pipehist_wide.reset_index(inplace=True)\n","pipe_cols = pipehist_wide.columns\n","remove_list = [\"Pipeline\", \"Pipeline_at_100_Percent\", \"Yield\"]\n","pipe_cols = difflist(projectactuals_cols, remove_list)\n","#print(pipe_cols)\n","    \n","numeric_cols_pipe = numeric_cols\n","numeric_cols_pipe = numeric_cols_pipe + pipe_cols\n","print(numeric_cols_pipe)\n","\n","numeric_cols = numeric_cols_pipe\n","pipehist_wide = convert_date_cols(pipehist_wide)\n","pipehist_wide = coerce_to_numeric(pipehist_wide)\n","pipehist_wide = coerce_to_int(pipehist_wide)\n","\n","pipehist_wide = pipehist_wide.sort_values(by=[\"End_of_Month\", \"Snapshot_Date\", \"Sub_Region_Code\"]).reset_index(drop=True)\n","\n","# print(' pipehist_wide: ')\n","\n","# pipehist_wide.query('Fin_Entity_ID==@entity_debug')\n","print(\"Pipehist_wide:\", pipehist_wide.shape)\n","\n","pd.DataFrame(pipehist_wide.describe(include='all').transpose().head())\n","\n","#pipehist_wide.tail()  # .query('Relative_Snapshot_Month_Offset == 0')\n","\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"33da2b2c-ca02-414f-bb64-599f1df2d61b"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":["\n","# FINAL MERGE\n","print(\"Preparing merge_final\")\n","pipehist_wide1 = pipehist_wide.copy()\n","merge_df2 = pd.merge(\n","    pipehist_wide1,\n","    pipetrend1,\n","    how=\"left\",\n","    on=[\"End_of_Month\", \"Snapshot_Date\", \"Sub_Region_Code\"],\n",").fillna(nan_value)\n","\n","display(merge_df2.tail())\n","\n","merge_final = pd.merge(\n","    merge_df1,\n","    merge_df2,\n","    how=\"left\",\n","    on=[\n","        \"End_of_Month\",\n","        \"Relative_Month_Offset\",\n","        \"Snapshot_Date\",\n","        \"Relative_Snapshot_Month_Offset\",\n","        \"Sub_Region_Code\",\n","    ],\n",").fillna(nan_value)\n","# print(merge_final.info())\n","# print(merge_final.tail())\n","# merge_final.drop(columns=['Snapshot_Date_Short','Relative_Snapshot_Month_Offset'], axis=1, inplace = True)\n","# New Code end\n","#display(merge_final.tail())\n","merge_final = merge_final.infer_objects()\n","merge_final = convert_date_cols(merge_final)\n","merge_final = coerce_to_numeric(merge_final)\n","merge_final = coerce_to_int(merge_final)\n","\n","merge_final = merge_final.sort_values(by=sort_cols_snp).reset_index(drop=True)\n","\n","\n","merge_final.to_csv(output_data_path + \"merge_final.csv\", index=False)\n","merge_final.to_parquet(output_data_path + \"merge_final.parquet\", index=None)\n","\"\"\"\n","#merge_final_sdf = spark.createDataFrame(merge_final);\n","#merge_final_sdf.repartition(1).write.format(\"parquet\").mode(\"overwrite\").parquet(output_data_path + 'merge_final.parquet')\n","\"\"\"\n","print(\"merge_final:\", merge_final.shape)\n","# merge_final.tail()\n","#print(merge_final[\"Snapshot_Date\"].unique())\n","# merge_final.query('Relative_Snapshot_Month_Offset == 0')\n","# show_stats(merge_final)\n","\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"eee0e27c-9889-4766-9a93-b8a396f2d6f4"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":["merge_final.query('Relative_Offset == 0 and Snp_Seq_No == 6').tail()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"6de6b547-ef16-466b-a75a-47e4220f0086"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":["pd.DataFrame(merge_final.describe(include='all').transpose().head())"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"f4b9acd6-32aa-4112-afee-accdec36b492"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":[],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"035374d6-0d4e-48d2-aace-8b6498f93e16"}},"outputs":[],"execution_count":null}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"data_prep_rev_region_forecast","dashboards":[],"notebookMetadata":{"pythonIndentUnit":4},"language":"python","widgets":{"new_training":{"nuid":"b6b051dd-8798-4160-ab56-ca50890c2387","currentValue":"False","widgetInfo":{"widgetType":"dropdown","name":"new_training","defaultValue":"False","label":null,"options":{"widgetType":"dropdown","choices":["True","False"]}}},"system_name":{"nuid":"94e67f26-cb39-4f3a-a350-31339f4f0ab4","currentValue":"bimodelapi","widgetInfo":{"widgetType":"dropdown","name":"system_name","defaultValue":"bimodelapi","label":null,"options":{"widgetType":"dropdown","choices":["bimodelapi"]}}},"environment":{"nuid":"73081d5c-71d3-4b16-a809-e71310329c7d","currentValue":"dev","widgetInfo":{"widgetType":"dropdown","name":"environment","defaultValue":"dev","label":null,"options":{"widgetType":"dropdown","choices":["dev","uat","prod"]}}}},"notebookOrigID":1689033015852655}},"nbformat":4,"nbformat_minor":0}